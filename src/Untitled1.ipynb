{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46fdb461-27a9-40de-b905-99bb93a95424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pandas as pd\n",
    "import stone\n",
    "\n",
    "dataset_folderpath = Path(\"/dataset\")\n",
    "output_folderpath = Path(\"/output\")\n",
    "\n",
    "split_filepath = dataset_folderpath / \"YouTubeFaces\" / \"meta_data\"/ \"meta_and_splits.mat\"\n",
    "videos_folderpath = dataset_folderpath / \"YouTubeFaces\" / \"frame_images_DB\"\n",
    "metadata_output_filepath = output_folderpath / \"metadata.csv\"\n",
    "gender_metadata_folder = dataset_folderpath / \"Additional_Labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f12dd4b-b672-4fd8-bb90-b3a6ce8f1598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "females.txt\n",
      "males.txt\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "ls /dataset/Additional_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04a67559-671f-48a1-b089-7e53d8d2811e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('Sadie_Frost/1', 'Sadie_Frost/5', 1),\n",
       "  ('Saied_Hadi_al_Mudarissi/0', 'Saied_Hadi_al_Mudarissi/2', 1),\n",
       "  ('Lucio_Stanca/3', 'Lucio_Stanca/4', 1),\n",
       "  ('Mary_Carey/0', 'Mary_Carey/4', 1),\n",
       "  ('Liu_Ye/0', 'Liu_Ye/5', 1)],\n",
       " [('Chris_Rock/1', 'Einars_Repse/4', 0),\n",
       "  ('Beatriz_Merino/2', 'Tim_Howard/0', 0),\n",
       "  ('Frank_Caliendo/1', 'Paul_Reiser/2', 0),\n",
       "  ('Bertie_Ahern/1', 'Festus_Mogae/1', 0),\n",
       "  ('Ben_Curtis/0', 'Hank_Stram/4', 0)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Read the triplets describing whether two videos feature the same face or not from the corresponding MatLab file.\n",
    "According to the dataset doc:\n",
    "'The Splits is a data structure dividing the data set to 10 independent splits.\n",
    "Each triplet in the Splits is in the format of (index1, index2, is_same_person), where index1 and index2 are the indices in the mat_names structure.\n",
    "All together 5000 pairs divided equaly to 10 independent splits, with 2500 same pairs and 2500 not-same pairs.'\n",
    "\"\"\"\n",
    "def read_triplets_from_file(mat_filepath:str) -> list[tuple[str, str, int]]:\n",
    "    # Read the MatLab file containing the list of splits\n",
    "    data_dict = loadmat(mat_filepath)\n",
    "\n",
    "    result = []\n",
    "    for split_list in data_dict['Splits']:\n",
    "        for video_index_1, video_index_2, is_same_person in zip(*split_list):\n",
    "            # The file was generated in MatLab where indexes start at 1, whereas they begin at 0 in Python\n",
    "            video_index_1 -= 1\n",
    "            video_index_2 -= 1\n",
    "            \n",
    "            result.append((data_dict['video_names'][video_index_1][0][0], data_dict['video_names'][video_index_2][0][0], is_same_person))\n",
    "\n",
    "    return result\n",
    "\n",
    "triplets = read_triplets_from_file(split_filepath)\n",
    "triplets[:5], triplets[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a25f054a-729f-4fae-bb79-d66edb017ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [01:35<00:00, 52.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\"\"\"\n",
    "For a given video, choose randomly one or more images (default=1) from that video.\n",
    "Also, extracts the position of the face in the chosen images.\n",
    "In the YouTubeFaces dataset, this position does not need to be predicted as it is given in the \"{celeb_name}.labeled_faces.txt\" file.\n",
    "Store those information as a dictionary along the name of the subject.\n",
    "\"\"\"\n",
    "def choose_image_and_find_face_location(video_name:str, nb_images:int=1) -> list[dict]:\n",
    "    # Chose an image in the video\n",
    "    video_folderpath = videos_folderpath / video_name\n",
    "    all_images = list(video_folderpath.iterdir())\n",
    "    chosen_images = random.sample(all_images, nb_images)\n",
    "    \n",
    "    # Find the location of the face in each of the image\n",
    "    celeb_name = video_name.split('/')[0]\n",
    "    face_location_filepath = videos_folderpath / f\"{celeb_name}.labeled_faces.txt\"\n",
    "    df = pd.read_csv(face_location_filepath, sep=',', header=None, index_col=0, names=[\"key\", \"x\", \"y\", \"width\", \"height\"], usecols=[0,2,3,4,5])\n",
    "    face_positions = []\n",
    "    for img_filepath in chosen_images:\n",
    "        # Convert the image filepath to the format used as a key in the \"{celeb_name}.labeled_faces.txt\" file\n",
    "        img_key = str(img_filepath).replace(str(videos_folderpath), '')[1:].replace(\"/\", \"\\\\\")\n",
    "        face_positions.append(df.loc[img_key].to_dict())\n",
    "\n",
    "    # Format the result as a list of dictionary\n",
    "    result = []\n",
    "    for img_filepath, face_position in zip(chosen_images, face_positions):\n",
    "        face_position[\"filepath\"] = img_filepath\n",
    "        face_position[\"subject_name\"] = celeb_name\n",
    "        result.append(face_position)\n",
    "\n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "For each triplet:\n",
    "- Select a single image to represent each of the two videos and find its filepath\n",
    "- Find the position of the face of the subject in each image.\n",
    "- Keep track of the name of the subject\n",
    "\"\"\"\n",
    "def expand_triplets(triplet_list:list[tuple]) -> list[dict]:\n",
    "    new_triplet_list = []\n",
    "    for video_name_1, video_name_2, label in tqdm(triplet_list):\n",
    "        if video_name_1 == video_name_2:\n",
    "            # To make sure the image selected is not the same, we sample two images of the video at once\n",
    "            info = choose_image_and_find_face_location(video_name_1, 2)\n",
    "            new_triplet_list.append((info[0], info[1], label))\n",
    "        else:\n",
    "            info1 = choose_image_and_find_face_location(video_name_1, 1)[0]\n",
    "            info2 = choose_image_and_find_face_location(video_name_2, 1)[0]\n",
    "            new_triplet_list.append((info1, info2, label))\n",
    "\n",
    "    return new_triplet_list\n",
    "        \n",
    "new_triplets = expand_triplets(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dba682e-63a9-42ca-9474-9f3e4bef0821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>width_1</th>\n",
       "      <th>height_1</th>\n",
       "      <th>filepath_1</th>\n",
       "      <th>subject_name_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>width_2</th>\n",
       "      <th>height_2</th>\n",
       "      <th>filepath_2</th>\n",
       "      <th>subject_name_2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>152</td>\n",
       "      <td>147</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Sadie_Fr...</td>\n",
       "      <td>Sadie_Frost</td>\n",
       "      <td>159</td>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Sadie_Fr...</td>\n",
       "      <td>Sadie_Frost</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174</td>\n",
       "      <td>89</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Saied_Ha...</td>\n",
       "      <td>Saied_Hadi_al_Mudarissi</td>\n",
       "      <td>174</td>\n",
       "      <td>86</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Saied_Ha...</td>\n",
       "      <td>Saied_Hadi_al_Mudarissi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>246</td>\n",
       "      <td>152</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Lucio_St...</td>\n",
       "      <td>Lucio_Stanca</td>\n",
       "      <td>187</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Lucio_St...</td>\n",
       "      <td>Lucio_Stanca</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>228</td>\n",
       "      <td>93</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Mary_Car...</td>\n",
       "      <td>Mary_Carey</td>\n",
       "      <td>160</td>\n",
       "      <td>137</td>\n",
       "      <td>153</td>\n",
       "      <td>153</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Mary_Car...</td>\n",
       "      <td>Mary_Carey</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>242</td>\n",
       "      <td>140</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Liu_Ye/0...</td>\n",
       "      <td>Liu_Ye</td>\n",
       "      <td>142</td>\n",
       "      <td>97</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Liu_Ye/5...</td>\n",
       "      <td>Liu_Ye</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>173</td>\n",
       "      <td>102</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Chris_Ro...</td>\n",
       "      <td>Chris_Rock</td>\n",
       "      <td>212</td>\n",
       "      <td>92</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Einars_R...</td>\n",
       "      <td>Einars_Repse</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>187</td>\n",
       "      <td>114</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Beatriz_...</td>\n",
       "      <td>Beatriz_Merino</td>\n",
       "      <td>208</td>\n",
       "      <td>80</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Tim_Howa...</td>\n",
       "      <td>Tim_Howard</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>135</td>\n",
       "      <td>53</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Frank_Ca...</td>\n",
       "      <td>Frank_Caliendo</td>\n",
       "      <td>158</td>\n",
       "      <td>87</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Paul_Rei...</td>\n",
       "      <td>Paul_Reiser</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>131</td>\n",
       "      <td>72</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Bertie_A...</td>\n",
       "      <td>Bertie_Ahern</td>\n",
       "      <td>172</td>\n",
       "      <td>64</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Festus_M...</td>\n",
       "      <td>Festus_Mogae</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>270</td>\n",
       "      <td>144</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Ben_Curt...</td>\n",
       "      <td>Ben_Curtis</td>\n",
       "      <td>235</td>\n",
       "      <td>91</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Hank_Str...</td>\n",
       "      <td>Hank_Stram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x_1  y_1  width_1  height_1  \\\n",
       "0     152  147      124       124   \n",
       "1     174   89       56        56   \n",
       "2     246  152      120       120   \n",
       "3     228   93      115       115   \n",
       "4     242  140      112       112   \n",
       "...   ...  ...      ...       ...   \n",
       "4995  173  102       56        56   \n",
       "4996  187  114       61        61   \n",
       "4997  135   53       47        47   \n",
       "4998  131   72       70        70   \n",
       "4999  270  144      130       130   \n",
       "\n",
       "                                             filepath_1  \\\n",
       "0     /dataset/YouTubeFaces/frame_images_DB/Sadie_Fr...   \n",
       "1     /dataset/YouTubeFaces/frame_images_DB/Saied_Ha...   \n",
       "2     /dataset/YouTubeFaces/frame_images_DB/Lucio_St...   \n",
       "3     /dataset/YouTubeFaces/frame_images_DB/Mary_Car...   \n",
       "4     /dataset/YouTubeFaces/frame_images_DB/Liu_Ye/0...   \n",
       "...                                                 ...   \n",
       "4995  /dataset/YouTubeFaces/frame_images_DB/Chris_Ro...   \n",
       "4996  /dataset/YouTubeFaces/frame_images_DB/Beatriz_...   \n",
       "4997  /dataset/YouTubeFaces/frame_images_DB/Frank_Ca...   \n",
       "4998  /dataset/YouTubeFaces/frame_images_DB/Bertie_A...   \n",
       "4999  /dataset/YouTubeFaces/frame_images_DB/Ben_Curt...   \n",
       "\n",
       "               subject_name_1  x_2  y_2  width_2  height_2  \\\n",
       "0                 Sadie_Frost  159   50       53        53   \n",
       "1     Saied_Hadi_al_Mudarissi  174   86       54        54   \n",
       "2                Lucio_Stanca  187   97       63        63   \n",
       "3                  Mary_Carey  160  137      153       153   \n",
       "4                      Liu_Ye  142   97      106       106   \n",
       "...                       ...  ...  ...      ...       ...   \n",
       "4995               Chris_Rock  212   92      103       103   \n",
       "4996           Beatriz_Merino  208   80       67        67   \n",
       "4997           Frank_Caliendo  158   87       76        76   \n",
       "4998             Bertie_Ahern  172   64       29        29   \n",
       "4999               Ben_Curtis  235   91       98        98   \n",
       "\n",
       "                                             filepath_2  \\\n",
       "0     /dataset/YouTubeFaces/frame_images_DB/Sadie_Fr...   \n",
       "1     /dataset/YouTubeFaces/frame_images_DB/Saied_Ha...   \n",
       "2     /dataset/YouTubeFaces/frame_images_DB/Lucio_St...   \n",
       "3     /dataset/YouTubeFaces/frame_images_DB/Mary_Car...   \n",
       "4     /dataset/YouTubeFaces/frame_images_DB/Liu_Ye/5...   \n",
       "...                                                 ...   \n",
       "4995  /dataset/YouTubeFaces/frame_images_DB/Einars_R...   \n",
       "4996  /dataset/YouTubeFaces/frame_images_DB/Tim_Howa...   \n",
       "4997  /dataset/YouTubeFaces/frame_images_DB/Paul_Rei...   \n",
       "4998  /dataset/YouTubeFaces/frame_images_DB/Festus_M...   \n",
       "4999  /dataset/YouTubeFaces/frame_images_DB/Hank_Str...   \n",
       "\n",
       "               subject_name_2  label  \n",
       "0                 Sadie_Frost      1  \n",
       "1     Saied_Hadi_al_Mudarissi      1  \n",
       "2                Lucio_Stanca      1  \n",
       "3                  Mary_Carey      1  \n",
       "4                      Liu_Ye      1  \n",
       "...                       ...    ...  \n",
       "4995             Einars_Repse      0  \n",
       "4996               Tim_Howard      0  \n",
       "4997              Paul_Reiser      0  \n",
       "4998             Festus_Mogae      0  \n",
       "4999               Hank_Stram      0  \n",
       "\n",
       "[5000 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format the data as a Pandas Dataframe so it can be exported easily to a '.csv' file and for ease of analysis\n",
    "series_list = []\n",
    "for i, triplet in enumerate(new_triplets):\n",
    "    series_1 = pd.Series(triplet[0]).add_suffix(\"_1\")\n",
    "    series_2 = pd.Series(triplet[1]).add_suffix(\"_2\")\n",
    "    series_3 = pd.Series({\"label\": triplet[2]})\n",
    "    row = pd.concat([series_1, series_2, series_3])\n",
    "    series_list.append(row)\n",
    "metadata_df = pd.DataFrame(series_list)\n",
    "metadata_df.to_csv(metadata_output_filepath, index=False)\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2a51833-8eea-4e5c-bd4c-8ad396019065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>width_1</th>\n",
       "      <th>height_1</th>\n",
       "      <th>filepath_1</th>\n",
       "      <th>subject_name_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>width_2</th>\n",
       "      <th>height_2</th>\n",
       "      <th>filepath_2</th>\n",
       "      <th>subject_name_2</th>\n",
       "      <th>label</th>\n",
       "      <th>gender_1</th>\n",
       "      <th>gender_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>152</td>\n",
       "      <td>147</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Sadie_Fr...</td>\n",
       "      <td>Sadie_Frost</td>\n",
       "      <td>159</td>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Sadie_Fr...</td>\n",
       "      <td>Sadie_Frost</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174</td>\n",
       "      <td>89</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Saied_Ha...</td>\n",
       "      <td>Saied_Hadi_al_Mudarissi</td>\n",
       "      <td>174</td>\n",
       "      <td>86</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Saied_Ha...</td>\n",
       "      <td>Saied_Hadi_al_Mudarissi</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>246</td>\n",
       "      <td>152</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Lucio_St...</td>\n",
       "      <td>Lucio_Stanca</td>\n",
       "      <td>187</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Lucio_St...</td>\n",
       "      <td>Lucio_Stanca</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>228</td>\n",
       "      <td>93</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Mary_Car...</td>\n",
       "      <td>Mary_Carey</td>\n",
       "      <td>160</td>\n",
       "      <td>137</td>\n",
       "      <td>153</td>\n",
       "      <td>153</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Mary_Car...</td>\n",
       "      <td>Mary_Carey</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>242</td>\n",
       "      <td>140</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Liu_Ye/0...</td>\n",
       "      <td>Liu_Ye</td>\n",
       "      <td>142</td>\n",
       "      <td>97</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Liu_Ye/5...</td>\n",
       "      <td>Liu_Ye</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>173</td>\n",
       "      <td>102</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Chris_Ro...</td>\n",
       "      <td>Chris_Rock</td>\n",
       "      <td>212</td>\n",
       "      <td>92</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Einars_R...</td>\n",
       "      <td>Einars_Repse</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>187</td>\n",
       "      <td>114</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Beatriz_...</td>\n",
       "      <td>Beatriz_Merino</td>\n",
       "      <td>208</td>\n",
       "      <td>80</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Tim_Howa...</td>\n",
       "      <td>Tim_Howard</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>135</td>\n",
       "      <td>53</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Frank_Ca...</td>\n",
       "      <td>Frank_Caliendo</td>\n",
       "      <td>158</td>\n",
       "      <td>87</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Paul_Rei...</td>\n",
       "      <td>Paul_Reiser</td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>131</td>\n",
       "      <td>72</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Bertie_A...</td>\n",
       "      <td>Bertie_Ahern</td>\n",
       "      <td>172</td>\n",
       "      <td>64</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Festus_M...</td>\n",
       "      <td>Festus_Mogae</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>270</td>\n",
       "      <td>144</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Ben_Curt...</td>\n",
       "      <td>Ben_Curtis</td>\n",
       "      <td>235</td>\n",
       "      <td>91</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>/dataset/YouTubeFaces/frame_images_DB/Hank_Str...</td>\n",
       "      <td>Hank_Stram</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x_1  y_1  width_1  height_1  \\\n",
       "0     152  147      124       124   \n",
       "1     174   89       56        56   \n",
       "2     246  152      120       120   \n",
       "3     228   93      115       115   \n",
       "4     242  140      112       112   \n",
       "...   ...  ...      ...       ...   \n",
       "4995  173  102       56        56   \n",
       "4996  187  114       61        61   \n",
       "4997  135   53       47        47   \n",
       "4998  131   72       70        70   \n",
       "4999  270  144      130       130   \n",
       "\n",
       "                                             filepath_1  \\\n",
       "0     /dataset/YouTubeFaces/frame_images_DB/Sadie_Fr...   \n",
       "1     /dataset/YouTubeFaces/frame_images_DB/Saied_Ha...   \n",
       "2     /dataset/YouTubeFaces/frame_images_DB/Lucio_St...   \n",
       "3     /dataset/YouTubeFaces/frame_images_DB/Mary_Car...   \n",
       "4     /dataset/YouTubeFaces/frame_images_DB/Liu_Ye/0...   \n",
       "...                                                 ...   \n",
       "4995  /dataset/YouTubeFaces/frame_images_DB/Chris_Ro...   \n",
       "4996  /dataset/YouTubeFaces/frame_images_DB/Beatriz_...   \n",
       "4997  /dataset/YouTubeFaces/frame_images_DB/Frank_Ca...   \n",
       "4998  /dataset/YouTubeFaces/frame_images_DB/Bertie_A...   \n",
       "4999  /dataset/YouTubeFaces/frame_images_DB/Ben_Curt...   \n",
       "\n",
       "               subject_name_1  x_2  y_2  width_2  height_2  \\\n",
       "0                 Sadie_Frost  159   50       53        53   \n",
       "1     Saied_Hadi_al_Mudarissi  174   86       54        54   \n",
       "2                Lucio_Stanca  187   97       63        63   \n",
       "3                  Mary_Carey  160  137      153       153   \n",
       "4                      Liu_Ye  142   97      106       106   \n",
       "...                       ...  ...  ...      ...       ...   \n",
       "4995               Chris_Rock  212   92      103       103   \n",
       "4996           Beatriz_Merino  208   80       67        67   \n",
       "4997           Frank_Caliendo  158   87       76        76   \n",
       "4998             Bertie_Ahern  172   64       29        29   \n",
       "4999               Ben_Curtis  235   91       98        98   \n",
       "\n",
       "                                             filepath_2  \\\n",
       "0     /dataset/YouTubeFaces/frame_images_DB/Sadie_Fr...   \n",
       "1     /dataset/YouTubeFaces/frame_images_DB/Saied_Ha...   \n",
       "2     /dataset/YouTubeFaces/frame_images_DB/Lucio_St...   \n",
       "3     /dataset/YouTubeFaces/frame_images_DB/Mary_Car...   \n",
       "4     /dataset/YouTubeFaces/frame_images_DB/Liu_Ye/5...   \n",
       "...                                                 ...   \n",
       "4995  /dataset/YouTubeFaces/frame_images_DB/Einars_R...   \n",
       "4996  /dataset/YouTubeFaces/frame_images_DB/Tim_Howa...   \n",
       "4997  /dataset/YouTubeFaces/frame_images_DB/Paul_Rei...   \n",
       "4998  /dataset/YouTubeFaces/frame_images_DB/Festus_M...   \n",
       "4999  /dataset/YouTubeFaces/frame_images_DB/Hank_Str...   \n",
       "\n",
       "               subject_name_2  label gender_1 gender_2  \n",
       "0                 Sadie_Frost      1        F        F  \n",
       "1     Saied_Hadi_al_Mudarissi      1        M        M  \n",
       "2                Lucio_Stanca      1        M        M  \n",
       "3                  Mary_Carey      1        F        F  \n",
       "4                      Liu_Ye      1        M        M  \n",
       "...                       ...    ...      ...      ...  \n",
       "4995             Einars_Repse      0        M        M  \n",
       "4996               Tim_Howard      0        F        M  \n",
       "4997              Paul_Reiser      0      N/A        M  \n",
       "4998             Festus_Mogae      0        M        M  \n",
       "4999               Hank_Stram      0        M        M  \n",
       "\n",
       "[5000 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_gender_file(gender_filepath:Path) -> set:\n",
    "    lines = gender_filepath.read_text().splitlines()\n",
    "\n",
    "    name_set = set()\n",
    "    for line in lines:\n",
    "        name = \"_\".join(line.split(\"_\")[:-1]) # Remove the suffix and extension of the filename to get the name of the subject\n",
    "        name_set.add(name)\n",
    "\n",
    "    return name_set\n",
    "\n",
    "def compute_gender_lists(gender_folderpath:Path) -> tuple[set, set]:\n",
    "    female_gender_filepath = gender_folderpath / \"females.txt\"\n",
    "    male_gender_filepath = gender_folderpath / \"males.txt\"\n",
    "\n",
    "    return parse_gender_file(female_gender_filepath), parse_gender_file(male_gender_filepath)\n",
    "\n",
    "def find_gender(name:str) -> str:\n",
    "    if name in female_set:\n",
    "        gender = \"F\"\n",
    "    elif name in male_set:\n",
    "        gender = \"M\"\n",
    "    else:\n",
    "        gender = \"N/A\"\n",
    "    return gender\n",
    "\n",
    "female_set, male_set = compute_gender_lists(gender_metadata_folder)\n",
    "metadata_df[\"gender_1\"] = metadata_df[\"subject_name_1\"].apply(find_gender)\n",
    "metadata_df[\"gender_2\"] = metadata_df[\"subject_name_2\"].apply(find_gender)\n",
    "metadata_df.to_csv(metadata_output_filepath, index=False)\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edcac16e-17fa-46f8-b3bc-0363fadb42a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [04:45<00:00, 17.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [04:44<00:00, 17.57it/s]\n"
     ]
    }
   ],
   "source": [
    "def predict_skin_tone(img_filepath:Path):\n",
    "    # From original filepath, find related cropped/aligned image\n",
    "    img_filepath = str(img_filepath)\n",
    "    img_filepath = img_filepath.replace(\"frame_images_DB\", \"aligned_images_DB\")\n",
    "    img_filepath = img_filepath.split(\"/\")\n",
    "    img_filepath[-1] = \"aligned_detect_\" + img_filepath[-1]\n",
    "    img_filepath = Path(\"/\".join(img_filepath))\n",
    "\n",
    "    # Predict skin tone from cropped/aligned image\n",
    "    info_dict = stone.process(img_filepath, image_type=\"color\")\n",
    "    skin_tone = info_dict[\"faces\"][0][\"skin_tone\"]\n",
    "\n",
    "    return skin_tone\n",
    "\n",
    "tqdm.pandas()\n",
    "metadata_df[\"skin_tone_1\"] = metadata_df[\"filepath_1\"].progress_apply(predict_skin_tone)\n",
    "metadata_df[\"skin_tone_2\"] = metadata_df[\"filepath_2\"].progress_apply(predict_skin_tone)\n",
    "metadata_df.to_csv(metadata_output_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "332898db-da1e-44a3-a879-8c633cc2890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df.to_csv(metadata_output_filepath, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
